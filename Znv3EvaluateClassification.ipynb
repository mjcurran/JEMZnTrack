{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0b115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t, torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision as tv, torchvision.transforms as tr\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "from jemsharedclasses import Base, JEMUtils, F2, CCF, DataSubset\n",
    "import pdb\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import genfromtxt\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from zntrack import ZnTrackProject, Node, config, dvc, zn\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from zntrack.metadata import TimeIt\n",
    "from eval_args import eval_args\n",
    "from src.XEntropyAugmented import XEntropyAugmented\n",
    "from src.MaxEntropyL1 import MaxEntropyL1\n",
    "from src.MaxEntropyL2 import MaxEntropyL2\n",
    "\n",
    "\n",
    "\n",
    "config.nb_name = \"Znv3EvaluateClassification.ipynb\"\n",
    "project = ZnTrackProject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92d400c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalCalibration(Base):\n",
    "    \n",
    "    def compute(self, inp, params):\n",
    "        args = inp\n",
    "        if not os.path.exists(params.save_dir):\n",
    "            os.makedirs(params.save_dir)\n",
    "        \n",
    "        if params.print_to_log:\n",
    "            sys.stdout = open(f'{os.path.join(params.save_dir, args.experiment)}/log.txt', 'w')\n",
    "\n",
    "        if not os.path.exists(os.path.join(params.save_dir, args.experiment)):\n",
    "            os.makedirs(os.path.join(params.save_dir, args.experiment))\n",
    "\n",
    "        t.manual_seed(params.seed)\n",
    "        if t.cuda.is_available():\n",
    "            t.cuda.manual_seed_all(params.seed)\n",
    "\n",
    "        device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "\n",
    "        model_cls = F2 if params.uncond else CCF\n",
    "        f = model_cls(params.depth, params.width, params.norm)\n",
    "        print(f\"loading model from {os.path.join(os.path.join(params.load_path, args.experiment), 'last_ckpt.pt')}\")\n",
    "\n",
    "        # load em up\n",
    "        ckpt_dict = t.load(os.path.join(os.path.join(params.load_path, args.experiment), 'last_ckpt.pt'))\n",
    "        f.load_state_dict(ckpt_dict[\"model_state_dict\"])\n",
    "        #replay_buffer = ckpt_dict[\"replay_buffer\"]\n",
    "\n",
    "        f = f.to(device)\n",
    "\n",
    "        # do calibration\n",
    "        resultfile = self.calibration(f, args, params, device)\n",
    "        return resultfile\n",
    "    \n",
    "    \n",
    "    def calibration(self, f, args, params, device):\n",
    "        transform_test = tr.Compose(\n",
    "            [tr.ToTensor(),\n",
    "             tr.Normalize((.5, .5, .5), (.5, .5, .5)),\n",
    "             lambda x: x + t.randn_like(x) * params.sigma]\n",
    "        )\n",
    "\n",
    "        def sample(x, n_steps=params.n_steps):\n",
    "            x_k = t.autograd.Variable(x.clone(), requires_grad=True)\n",
    "            # sgld\n",
    "            for k in range(n_steps):\n",
    "                f_prime = t.autograd.grad(f(x_k).sum(), [x_k], retain_graph=True)[0]\n",
    "                x_k.data += f_prime + 1e-2 * t.randn_like(x_k)\n",
    "            final_samples = x_k.detach()\n",
    "            return final_samples\n",
    "\n",
    "        if params.dataset == \"cifar_train\":\n",
    "            dset = tv.datasets.CIFAR10(root=params.data_root, transform=transform_test, download=True, train=True)\n",
    "        elif params.dataset == \"cifar_test\":\n",
    "            dset = tv.datasets.CIFAR10(root=params.data_root, transform=transform_test, download=True, train=False)\n",
    "        elif params.dataset == \"svhn_train\":\n",
    "            dset = tv.datasets.SVHN(root=params.data_root, transform=transform_test, download=True, split=\"train\")\n",
    "        else:  # args.dataset == \"svhn_test\":\n",
    "            dset = tv.datasets.SVHN(root=params.data_root, transform=transform_test, download=True, split=\"test\")\n",
    "\n",
    "        dload = DataLoader(dset, batch_size=1, shuffle=False, num_workers=4, drop_last=False)\n",
    "\n",
    "        start=0.05\n",
    "        step=.05\n",
    "        num=20\n",
    "\n",
    "        bins=np.arange(0,num)*step+start+ 1e-10\n",
    "        bin_total = np.zeros(20)+1e-5\n",
    "        bin_correct = np.zeros(20)\n",
    "\n",
    "        #energies, corrects, losses, pys, preds = [], [], [], [], []\n",
    "    \n",
    "        for x_p_d, y_p_d in tqdm(dload):\n",
    "            x_p_d, y_p_d = x_p_d.to(device), y_p_d.to(device)\n",
    "\n",
    "            logits = f.classify(x_p_d).detach().cpu()#.numpy()\n",
    "\n",
    "            py = nn.Softmax()(logits)[0].numpy()#(f.classify(x_p_d)).max(1)[0].detach().cpu().numpy()\n",
    "        \n",
    "            expected = y_p_d[0].detach().cpu().numpy()\n",
    "        \n",
    "            actual = logits.max(1)[1][0].numpy()\n",
    "        \n",
    "            #print(py[expected],expected,actual)\n",
    "        \n",
    "            inds = np.digitize(py[actual], bins)\n",
    "            bin_total[inds] += 1\n",
    "            if actual == expected:\n",
    "                bin_correct[inds] += 1\n",
    "            \n",
    "        #\n",
    "        accu = np.divide(bin_correct,bin_total)\n",
    "        print(\"Bin data\",np.sum(bin_total),accu,bins,bin_total)\n",
    "    \n",
    "        # calc ECE\n",
    "        ECE = 0.0\n",
    "        for i in range(20):\n",
    "            #print(\"accu\",accu[i],(i/20.0 + 0.025),bin_total[i])\n",
    "            ECE += (float(bin_total[i]) / float(np.sum(bin_total))) * abs(accu[i] - (i/20.0 + 0.025))\n",
    "        \n",
    "        print(\"ECE\", ECE)\n",
    "    \n",
    "        # save calibration  in a text file\n",
    "            \n",
    "        pd.DataFrame({'accuracy': accu, 'ECE': ECE}).to_csv(path_or_buf=os.path.join(params.save_dir, args.experiment) + \"_calibration.csv\", index_label=\"index\")\n",
    "        outputcsv = os.path.join(params.save_dir, args.experiment) + \"_calibration.csv\"\n",
    "        return outputcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29d265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateX(Node):\n",
    "    \n",
    "    #from the DVC docs:  \"Stage dependencies can be any file or directory\"\n",
    "    # so the eval_args stages have to output something in order to be used as deps here\n",
    "    # so we use the metrics files like:  nodes/x-entropy_augmented/metrics_no_cache.json\n",
    "    #args = dvc.deps([eval_args(load=True, name=\"x-entropy_augmented\"), \n",
    "    #                 eval_args(load=True, name=\"max-entropy-L1_augmented\"), \n",
    "    #                 eval_args(load=True, name=\"max-entropy-L2_augmented\")])\n",
    "\n",
    "    \n",
    "    #models = dvc.deps([XEntropyAugmented(load=True), MaxEntropyL1(load=True), MaxEntropyL2(load=True)])\n",
    "\n",
    "    #models = dvc.deps([XEntropyAugmented.load(), MaxEntropyL1.load(), MaxEntropyL2.load()])\n",
    "    models = dvc.deps([XEntropyAugmented(), MaxEntropyL1(), MaxEntropyL2()])\n",
    "    params: eval_args = zn.Method()\n",
    "    operation: Base = zn.Method()\n",
    "        \n",
    "    # add plots to dvc tracking\n",
    "    # this would be better if the paths could be defined by the passed args, but can't see how to \n",
    "    plot0: Path = dvc.plots_no_cache(\"./experiment/x-entropy_augmented_calibration.csv\")\n",
    "    plot1: Path = dvc.plots_no_cache(\"./experiment/max-entropy-L1_augmented_calibration.csv\")\n",
    "    plot2: Path = dvc.plots_no_cache(\"./experiment/max-entropy-L2_augmented_calibration.csv\")\n",
    "    #manually added template: confidence to the plots in dvc.yaml\n",
    "    \n",
    "    def __init__(self, params: eval_args = None, operation:Base = None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.params = params\n",
    "        self.operation = operation\n",
    "        if not self.is_loaded:\n",
    "            self.params = eval_args(experiment=\"energy_model\")\n",
    "    \n",
    "    \n",
    "\n",
    "    def run(self):\n",
    "        for arg in self.models:\n",
    "            self.operation.compute(arg, self.params)\n",
    "            #with open('./experiment/joint_energy_models_scores.json', 'a') as outfile:\n",
    "            #    json.dump(scores, outfile)\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f45866c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-25 16:10:44,563 (WARNING): Jupyter support is an experimental feature! Please save your notebook before running this command!\n",
      "Submit issues to https://github.com/zincware/ZnTrack.\n",
      "2022-01-25 16:10:44,563 (WARNING): Converting Znv3EvaluateClassification.ipynb to file EvaluateX.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Znv3EvaluateClassification.ipynb to script\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-25 16:10:46,555 (ERROR): Can not convert args!\n",
      "2022-01-25 16:10:46,555 (ERROR): Can not convert kwargs!\n",
      "2022-01-25 16:10:46,588 (WARNING): --- Writing new DVC file! ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Writing 7161 bytes to Znv3EvaluateClassification.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-25 16:10:47,647 (INFO): Modifying stage 'EvaluateX' in 'dvc.yaml'\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "    git add dvc.yaml\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EvaluateX(params=eval_args(), operation = EvalCalibration()).write_graph(no_exec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a7eeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running stage 'XEntropyAugmented':\n",
      "> python3 -c \"from src.XEntropyAugmented import XEntropyAugmented; XEntropyAugmented.load(name='XEntropyAugmented').run_and_save()\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/crc/python/03JEMZnTrack/__pypackages__/3.9/lib/zntrack/core/base.py\", line 86, in load\n",
      "    instance = cls(name=name, is_loaded=True)\n",
      "  File \"/Users/crc/python/03JEMZnTrack/src/XEntropyAugmented.py\", line 187, in __init__\n",
      "    self.metrics = Path(os.path.join(self.params.save_dir, self.params.experiment) + '_scores.json')\n",
      "  File \"/Users/crc/python/03JEMZnTrack/__pypackages__/3.9/lib/zntrack/zn/__init__.py\", line 178, in __get__\n",
      "    value.znjson_zn_method = True\n",
      "AttributeError: 'NoneType' object has no attribute 'znjson_zn_method'\n",
      "ERROR: failed to reproduce 'dvc.yaml': failed to run: python3 -c \"from src.XEntropyAugmented import XEntropyAugmented; XEntropyAugmented.load(name='XEntropyAugmented').run_and_save()\" , exited with 1\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['dvc', 'repro']' returned non-zero exit status 255.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepro\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python/03JEMZnTrack/__pypackages__/3.9/lib/zntrack/project/zntrack_project.py:113\u001b[0m, in \u001b[0;36mZnTrackProject.repro\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepro\u001b[39m():\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;124;03m\"\"\"Run dvc repro\"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdvc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/subprocess.py:373\u001b[0m, in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m popenargs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['dvc', 'repro']' returned non-zero exit status 255."
     ]
    }
   ],
   "source": [
    "project.repro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75b8d42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
